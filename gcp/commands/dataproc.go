package commands

import (
	"context"
	"fmt"
	"strings"
	"sync"

	dataprocservice "github.com/BishopFox/cloudfox/gcp/services/dataprocService"
	"github.com/BishopFox/cloudfox/globals"
	"github.com/BishopFox/cloudfox/internal"
	gcpinternal "github.com/BishopFox/cloudfox/internal/gcp"
	"github.com/spf13/cobra"
)

var GCPDataprocCommand = &cobra.Command{
	Use:     globals.GCP_DATAPROC_MODULE_NAME,
	Aliases: []string{"dp", "hadoop", "spark"},
	Short:   "Enumerate Dataproc clusters",
	Long: `Enumerate Dataproc (Hadoop/Spark) clusters.

Features:
- Lists all Dataproc clusters across regions
- Shows service account configuration
- Identifies public IP exposure
- Checks for Kerberos authentication
- Analyzes security configurations`,
	Run: runGCPDataprocCommand,
}

type DataprocModule struct {
	gcpinternal.BaseGCPModule
	Clusters []dataprocservice.ClusterInfo
	LootMap  map[string]*internal.LootFile
	mu       sync.Mutex
}

type DataprocOutput struct {
	Table []internal.TableFile
	Loot  []internal.LootFile
}

func (o DataprocOutput) TableFiles() []internal.TableFile { return o.Table }
func (o DataprocOutput) LootFiles() []internal.LootFile   { return o.Loot }

func runGCPDataprocCommand(cmd *cobra.Command, args []string) {
	cmdCtx, err := gcpinternal.InitializeCommandContext(cmd, globals.GCP_DATAPROC_MODULE_NAME)
	if err != nil {
		return
	}

	module := &DataprocModule{
		BaseGCPModule: gcpinternal.NewBaseGCPModule(cmdCtx),
		Clusters:      []dataprocservice.ClusterInfo{},
		LootMap:       make(map[string]*internal.LootFile),
	}
	module.initializeLootFiles()
	module.Execute(cmdCtx.Ctx, cmdCtx.Logger)
}

func (m *DataprocModule) Execute(ctx context.Context, logger internal.Logger) {
	m.RunProjectEnumeration(ctx, logger, m.ProjectIDs, globals.GCP_DATAPROC_MODULE_NAME, m.processProject)

	if len(m.Clusters) == 0 {
		logger.InfoM("No Dataproc clusters found", globals.GCP_DATAPROC_MODULE_NAME)
		return
	}

	runningCount := 0
	publicCount := 0
	for _, cluster := range m.Clusters {
		if cluster.State == "RUNNING" {
			runningCount++
		}
		if !cluster.InternalIPOnly {
			publicCount++
		}
	}

	logger.SuccessM(fmt.Sprintf("Found %d Dataproc cluster(s) (%d running, %d with public IPs)",
		len(m.Clusters), runningCount, publicCount), globals.GCP_DATAPROC_MODULE_NAME)
	m.writeOutput(ctx, logger)
}

func (m *DataprocModule) processProject(ctx context.Context, projectID string, logger internal.Logger) {
	if globals.GCP_VERBOSITY >= globals.GCP_VERBOSE_ERRORS {
		logger.InfoM(fmt.Sprintf("Enumerating Dataproc in project: %s", projectID), globals.GCP_DATAPROC_MODULE_NAME)
	}

	svc := dataprocservice.New()

	clusters, err := svc.ListClusters(projectID)
	if err != nil {
		m.CommandCounter.Error++
		gcpinternal.HandleGCPError(err, logger, globals.GCP_DATAPROC_MODULE_NAME,
			fmt.Sprintf("Could not list Dataproc clusters in project %s", projectID))
		return
	}

	m.mu.Lock()
	m.Clusters = append(m.Clusters, clusters...)
	for _, cluster := range clusters {
		m.addToLoot(cluster)
	}
	m.mu.Unlock()
}

func (m *DataprocModule) initializeLootFiles() {
	m.LootMap["dataproc-commands"] = &internal.LootFile{
		Name:     "dataproc-commands",
		Contents: "# Dataproc Commands\n# Generated by CloudFox\n\n",
	}
}

func (m *DataprocModule) addToLoot(cluster dataprocservice.ClusterInfo) {
	m.LootMap["dataproc-commands"].Contents += fmt.Sprintf(
		"# %s (%s)\n"+
			"# Project: %s\n",
		cluster.Name, cluster.Region,
		cluster.ProjectID,
	)

	// gcloud commands
	m.LootMap["dataproc-commands"].Contents += fmt.Sprintf(
		"gcloud dataproc clusters describe %s --region=%s --project=%s\n"+
			"gcloud dataproc jobs list --cluster=%s --region=%s --project=%s\n",
		cluster.Name, cluster.Region, cluster.ProjectID,
		cluster.Name, cluster.Region, cluster.ProjectID,
	)

	// Bucket commands
	if cluster.ConfigBucket != "" {
		m.LootMap["dataproc-commands"].Contents += fmt.Sprintf(
			"gsutil ls gs://%s/\n",
			cluster.ConfigBucket,
		)
	}
	if cluster.TempBucket != "" {
		m.LootMap["dataproc-commands"].Contents += fmt.Sprintf(
			"gsutil ls gs://%s/\n",
			cluster.TempBucket,
		)
	}

	m.LootMap["dataproc-commands"].Contents += "\n"
}

func (m *DataprocModule) writeOutput(ctx context.Context, logger internal.Logger) {
	// Single table with one row per IAM binding
	header := []string{
		"Project Name",
		"Project ID",
		"Name",
		"Region",
		"State",
		"Master",
		"Master Instances",
		"Workers",
		"Service Account",
		"Public IPs",
		"Kerberos",
		"IAM Role",
		"IAM Member",
	}

	var body [][]string
	for _, cluster := range m.Clusters {
		sa := cluster.ServiceAccount
		if sa == "" {
			sa = "(default)"
		}

		masterConfig := fmt.Sprintf("%s x%d", cluster.MasterMachineType, cluster.MasterCount)
		workerConfig := fmt.Sprintf("%s x%d", cluster.WorkerMachineType, cluster.WorkerCount)

		// Master instances
		masterInstances := "-"
		if len(cluster.MasterInstanceNames) > 0 {
			masterInstances = strings.Join(cluster.MasterInstanceNames, ", ")
		}

		// If cluster has IAM bindings, create one row per binding
		if len(cluster.IAMBindings) > 0 {
			for _, binding := range cluster.IAMBindings {
				body = append(body, []string{
					m.GetProjectName(cluster.ProjectID),
					cluster.ProjectID,
					cluster.Name,
					cluster.Region,
					cluster.State,
					masterConfig,
					masterInstances,
					workerConfig,
					sa,
					boolToYesNo(!cluster.InternalIPOnly),
					boolToYesNo(cluster.KerberosEnabled),
					binding.Role,
					binding.Member,
				})
			}
		} else {
			// Cluster has no IAM bindings - single row
			body = append(body, []string{
				m.GetProjectName(cluster.ProjectID),
				cluster.ProjectID,
				cluster.Name,
				cluster.Region,
				cluster.State,
				masterConfig,
				masterInstances,
				workerConfig,
				sa,
				boolToYesNo(!cluster.InternalIPOnly),
				boolToYesNo(cluster.KerberosEnabled),
				"-",
				"-",
			})
		}
	}

	tables := []internal.TableFile{{Name: "dataproc-clusters", Header: header, Body: body}}

	var lootFiles []internal.LootFile
	for _, loot := range m.LootMap {
		if loot.Contents != "" && !strings.HasSuffix(loot.Contents, "# Generated by CloudFox\n\n") {
			lootFiles = append(lootFiles, *loot)
		}
	}

	output := DataprocOutput{Table: tables, Loot: lootFiles}

	scopeNames := make([]string, len(m.ProjectIDs))
	for i, id := range m.ProjectIDs {
		scopeNames[i] = m.GetProjectName(id)
	}

	err := internal.HandleOutputSmart("gcp", m.Format, m.OutputDirectory, m.Verbosity, m.WrapTable,
		"project", m.ProjectIDs, scopeNames, m.Account, output)
	if err != nil {
		logger.ErrorM(fmt.Sprintf("Error writing output: %v", err), globals.GCP_DATAPROC_MODULE_NAME)
	}
}
